---
title: "Pollution Report (PM10)"
author: "Subhrajyoty Roy, Udit Surya Saha"
date: "21 July 2018"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

  This report is about a primary analysis of the Pollution dataset provided by West Bengal Pollution Control Board (WBPCB) and Central Pollution Control Board (CPCB), which contains the measurement of PM10 (Particular Matter), $SO_2$ (Sulphar dioxide) and $NO_2$ (Nitrogen dioxide), measured at the rooftop of Asansol Municipal Corporation. The dataset consists of irregularly spaced measurement of the above from January, 2001 to December, 2011 and from October, 2012 to January, 2017. This report only concerns about the analysis of PM10.
  
## Primary Scrutiny

  A primary scrutiny of the dataset shows that in row 169 of sheet 1, the date has been wrongly assigned as 28/05/2008 which should have been 28/05/2006. In row 18 of sheet 2, the date has been wrongly assigned as 13.10.2012 which should have been 13.11.2012.
  

## Preprocessing and Necessary Assumptions

  Some preprocessing has been done on the data to convert it into a necessary format. These includes;
  
* Removing the blank rows and rows containing metadata (unnecessary headings at the top of excel sheets).

* Reading only the necessary columns. (Also, it is worth to mention that the sheet 1 contains the data about SPM and RPM. Since, RPM (respirable particulate matter) are particulate matters (PM) of size 10 micrometers or smaller, it is regarded as PM10).

* Transforming the dataset into a time series by putting the data of shift1, shift2 and shift3 for a particular day, in this order.

* Since, the data about the time of measurements in various shifts are unavailable, it is assumed each shift divides the whole day in three equal parts. Therefore, shift2 measurement is assumed to be taken 8 hours after shift1 measurement, and similarly, shift3 measurement is assumed to be taken 8 hours after shift2 measurement.

* For the analysis of how PM10 exceeds the air quality standards, we use the PM10 breakpoint as 100 microgram per cubic meter, as specified in https://www.transportpolicy.net/standard/india-air-quality-standards/ .

  Let us take a look at the processed dataset.

```{r}
PM10data <- read.csv('PM10_All_shifts.csv')
names(PM10data) <- c("DateTime","PM.Values")
head(PM10data, 10)
```

  The "Datetime" column consists of the number of hours of a shift initializing the first observation time as origin. The "PM.Values" column contains the measurements of PM10.
  
```{r}
#This is some necessary variable creation
PM10data$DailyAvg <- 'NA'

#Create the daily averages
AvgIndex <- seq(2,nrow(PM10data), by=3)

for (i in AvgIndex) {
  PM10data$DailyAvg[i] <- mean(PM10data$PM.Values[(i-1):(i+1)])
}

##############################################################

#changing the datetime into number of days and reconstructing the shift time

PM10data$ShiftTime <- as.factor(((PM10data$DateTime %% 24)/8)+1)

PM10data$DateTime <- (PM10data$DateTime/24)
```

  Let us take a look at the data graphically.
  
```{r}
inputPanel(
  sliderInput("start_1", label = "Starting Point",
              min = 1, max = 3513, value = 1,step = 100),
  sliderInput("span_1", label = "Span",
              min = 100, max = 3513, value = 3513, step = 250)
)

renderPlot({
  plot(PM10data$DateTime[input$start_1:(input$start_1+input$span_1)],
       PM10data$PM.Values[input$start_1:(input$start_1+input$span_1)],
       type = "l", xlab = "Number of Days", ylab = "PM10 Measurements",
       main = "PM10 Measurements as Time Series")
  
  abline(h=100, col="red", lwd = 2)
})
```


## Analysis

  The analysis contains two main steps.

* Using a smoothing technique to smooth out the inter-daily variations, so that the smoother captures only fluctuations of daily averages.

* The residual part should capture the behavior of each shift individually and some random noise. Therefore, the residuals are split across different shifts and analyzed seperately.

  Firstly, we use a Gaussian Kernel smoothing technique to estimate the fluctuations of daily averages. 
  
```{r}
inputPanel(
  sliderInput("start_2", label = "Starting Point",
              min = 1, max = 3513, value = 1,step = 100),
  sliderInput("span_2", label = "Span",
              min = 100, max = 1000, value = 100, step = 50),
  sliderInput("band_2", label = "Bandwidth Level",
              min = 1, max = 15, step = 0.5, value = 1)
)

renderPlot({
  smoothed <- ksmooth(PM10data$DateTime, PM10data$PM.Values, kernel = "normal",
                      bandwidth = input$band_2)
  
  plot(PM10data$DateTime[input$start_2:(input$start_2+input$span_2)],
       PM10data$PM.Values[input$start_2:(input$start_2+input$span_2)],
       type = "l", xlab = "Number of Days", ylab = "PM10 Measurements",
       main = "PM10 Measurements as Time Series", col=rgb(0,0,0,0.7))
  
  points(smoothed, type = "l", col="red")
  
  points(PM10data$DateTime[AvgIndex], PM10data$DailyAvg[AvgIndex],
         type = "o", col="blue")
  
  legend("topleft",legend = c("PM10 Measurements","Smoothed Curve","Daily Averages"),col=c("black","red","blue"), lwd=1)
}, height = 500)
```


  It seems that smoothing with a bandwidth of 4.5 should be good enough for our purpose. 

  To check whether the bandwidth selection is "good", we plot the residual.
  
```{r}
daily_smoother <- ksmooth(PM10data$DateTime, PM10data$PM.Values, 
                          bandwidth = 4.5, kernel = "normal",
                          x.points = PM10data$DateTime)

PM10data$DailyError <- PM10data$PM.Values - daily_smoother$y[daily_smoother$x==PM10data$DateTime]

inputPanel(
  sliderInput("start_3", label = "Starting Point",
              min = 1, max = 3513, value = 1,step = 100),
  sliderInput("span_3", label = "Span",
              min = 100, max = 3513, value = 3513, step = 250)
)

renderPlot({
  plot(PM10data$DateTime[input$start_3:(input$start_3+input$span_3)],
       PM10data$DailyError[input$start_3:(input$start_3+input$span_3)],
       type = "l", xlab = "Number of Days", ylab = "Residuals after Smoothing",
       main = "Residual Plot")
  
  abline(h=0, col="blue", lwd=2)
})

```

  The residual plot, fortuantely, does not exihibit any definite pattern. Therefore, we may assume that our bandwidth selection is good. Also, notice that the variabilty of the residuals is large in the first part, then it decreases in the middle of the year and increases again. This suggests a use of robust smoothing technique to analyze the residuals.
  
  Now, we try to explore the properties of the daily smoother curve, and decompose it to find a periodic movement, other than the usual trend. 
  
```{r message = FALSE, warning=FALSE, fig.height=8}
library(zoo)

## the difference in 2005-01-01 to 2017-01-31 is 4412 days.

daily_smoother_regular <- ksmooth(PM10data$DateTime, PM10data$PM.Values, bandwidth = 4.5, kernel = "normal", x.points = seq(0.333, 4409.333, length.out = 4412))

smoothed_ts <- ts(na.approx(daily_smoother_regular$y), frequency = 365)

model <- decompose(smoothed_ts)
plot(model)

seasonal_coeff <- data.frame(dates = seq(as.Date("2001-01-01"), as.Date("2001-12-31"), by = "days"), coeff = model$seasonal[1:365])

seasonal_coeff$month <- months(seasonal_coeff$dates)
coeffs = sapply(split(seasonal_coeff$coeff, seasonal_coeff$month), mean)
print(sort(coeffs))
```
  
  Now, we split up the residuals based on their shifts and plot them individually. After that, we try to explore the pattern in residuals corresponding to a single shift and use robust smoothing technique (namely local polynomial LAD regression smoother) to find out how the general behavior of that shift differs from the general behavior of the day.
  
```{r}
ShiftList <- split(PM10data, PM10data$ShiftTime)

smoothed_plot <- function(i, bandwidth, startpoint, span){
smoothed <- loess(ShiftList[[i]]$DailyError ~ ShiftList[[i]]$DateTime, 
                      family = "symmetric",
                      span = bandwidth)
  plot(ShiftList[[i]]$DateTime[startpoint:(startpoint+span)],
       ShiftList[[i]]$DailyError[startpoint:(startpoint+span)], 
       type = "l", col=rgb(0,0,0,0.7), xlab = "", ylab = "")
  points(ShiftList[[i]]$DateTime[startpoint:(startpoint+span)],
         smoothed$fitted[startpoint:(startpoint+span)], 
         type = "l", col="red",lwd=2)
  abline(h=0, col="blue")
  title(xlab = "Number of Days",ylab = "Shift specific Residuals",
        main = "Residual Plot for different Shifts")
}

inputPanel(
  selectInput("shift", label = "Shift Id", choices = c(1,2,3)),
  
  sliderInput("start_4", label = "Starting Point",
              min = 1, max = 1171, value = 1,step = 100),
  sliderInput("span_4", label = "Span",
              min = 100, max = 1171, value = 600, step = 50),
  sliderInput("band_4", label = "Bandwidth Level",
              min = 0.01, max = 0.15, step = 0.005, value = 0.1)
)


renderPlot({
  smoothed_plot(input$shift, input$band_4, input$start_4, input$span_4)
})

```

  We fit the robust smoothing to these residuals of different shifts, with bandwidths 0.06, 0.07 and 0.08 respectively. These smoothed value over the residuals are added with the daily smoothed values, to procure the estimate of PM10 values at different time points. The residual plots for robust smoothing for individual shifts are given as follows:
  
```{r}
shift1_smoother <- loess(ShiftList[[1]]$DailyError ~ ShiftList[[1]]$DateTime, 
                         family = "symmetric",
                         span = 0.06)


shift2_smoother <- loess(ShiftList[[2]]$DailyError ~ ShiftList[[2]]$DateTime, 
                         family = "symmetric",
                         span = 0.07)


shift3_smoother <- loess(ShiftList[[3]]$DailyError ~ ShiftList[[3]]$DateTime, 
                         family = "symmetric",
                         span = 0.08)
shiftsmoothed_all <- list(shift1_smoother, shift2_smoother, shift3_smoother)

PM10data$Estimate <- daily_smoother$y[daily_smoother$x==PM10data$DateTime]

for (i in 1:nrow(PM10data)){
  PM10data$Estimate[i] <- PM10data$Estimate[i] + shiftsmoothed_all[[PM10data$ShiftTime[i]]]$fitted[ceiling(i/3)]
}

inputPanel(
  selectInput("shift_a",label = "Shift Id", choices = c(1,2,3))
)

renderPlot({
  plot(resid(shiftsmoothed_all[[as.numeric(input$shift_a)]]), type = "l", 
       xlim = c(0,1200), ylim = c(-150,220), ylab = "Residuals")
  abline(h=0, col="blue", lwd=2)
})

```

  Finally we plot the estimates along with the original data to see how good the estimates really are.
  
```{r}
inputPanel(
  sliderInput("start_5", label = "Starting Point",
              min = 1, max = 3513, value = 1,step = 100),
  sliderInput("span_5", label = "Span",
              min = 100, max = 3000, value = 100, step = 50),
  checkboxInput("displaymonths", label = "Display Months", value = FALSE)
)

renderPlot({
  plot(PM10data$DateTime[input$start_5:(input$start_5+input$span_5)],
       PM10data$PM.Values[input$start_5:(input$start_5+input$span_5)],
       type = "l", xlab = "Number of Days", ylab = "PM10 Measurements",
       main = "PM10 Measurements as Time Series", ylim = c(0, 600))
  
  points(PM10data$DateTime[input$start_5:(input$start_5+input$span_5)],
         PM10data$Estimate[input$start_5:(input$start_5+input$span_5)],
         type = "l", col="blue")
  
  abline(h=100, col="red", lwd=2)
  for (i in 1:9){
    abline(v=(365*i))
    text((365*i), 550, paste("Year", as.character(i+2004)))
    if (input$displaymonths) {
      for (j in 1:12){
        abline(v = ((365*(i-1))+(j*30)), col = "darkgreen", lty = 2)
        text(((365*(i-1))+(j*30) - 20), 580, month.name[j])
      }
    }
  }
  
  legend("topleft", legend = c("Original Data","Estimates","PM10 Tolerance Level"), 
         col = c("black","blue", "red"), lwd = 2)
})
```


  We see that the value of the PM10 falls below the regulation level at the middle of the year, from April-May to September-October.  

Now, let's look at the plot of autocorrelation function for different shifts.

```{r}

shift1_full_data <- data.frame(DateTime = 0:4409, DailyError=NA)
shift2_full_data <- data.frame(DateTime = 0:4409, DailyError=NA)
shift3_full_data <- data.frame(DateTime = 0:4409, DailyError=NA)
Shift_Full_List <- list(shift1_full_data, shift2_full_data, shift3_full_data)

for (i in 1:3){
  for (date in 0:4409) {
  if (date %in% ShiftList[[1]]$DateTime) {
    Shift_Full_List[[i]]$DailyError[which(Shift_Full_List[[i]]$DateTime==date)] = ShiftList[[i]]$DailyError[which(floor(ShiftList[[i]]$DateTime)==date)]
    }
  }
}

```


```{r}
inputPanel(
  selectInput("shift_b",label = "Shift",choices = c(1:3)),
  sliderInput("lag_span", label = "Maximum Lag", min = 30, max=380, step=25, value = 100),
  checkboxInput("partial","Partial AutoCorrelation Function",value = FALSE)
)

renderPlot({
  if(input$partial){
    pacf(ShiftList[[input$shift_b]]$DailyError, lag.max=input$lag_span)
  }
  
  else {
   acf(Shift_Full_List[[as.numeric(input$shift_b)]]$DailyError, lag.max=input$lag_span, na.action = na.pass) 
  }
    
})


```

 We observe some interesting repeatative periodic patterns here. The Acf shows that an abnormality in PM10 measures of shift1 stays effective for about 75 days. However, the partial autocorrelation function is a more justifiable measure in this case, which shows that the duration for which an abnormailty in PM10 measures of shift1 stays effective is about 2 weeks (**The ACF is plotted against the number of days as the lags, where the PACF is plotted against the number of lagged terms. On average, a lag spans over 3 days.**). Also, note that for shift2 and shift3, this correlation is not very strong.
 
 Now, we consider the periodicity of the shift-specific errors.
 
```{r}
inputPanel(
  selectInput("shift_c", label="Shift", choices = c(1:3)),
  sliderInput("max_freq", label = "Maximum Frequency", min = 0.025, max= 1, step = 0.05, value = 1)
)

renderPlot({
  model <- spectrum(ShiftList[[input$shift_c]]$DailyError,log="no", plot=FALSE)
  plot(model, log="no", xlim = c(0,input$max_freq))
})
```

  We observe that the period should be the datetime corresponding to the inverse frequency for which the spectrum is the largest. However, since the time series is irregular, a more typical thing would be to take the weighted average of the datetimes corresponding to the inverse frequencies, where the weights are the spectrum values of those frequencies.
  
```{r}
inputPanel(
    selectInput("shift_d", label="Shift", choices = c(1:3))
)

renderDataTable({
  model <- spectrum(ShiftList[[input$shift_d]]$DailyError,log="no", plot=FALSE)
  model <- data.frame(freq = model$freq, spec = model$spec)
  model <- model[order(model$spec, decreasing = TRUE)[1:5],] #we select only largest 5 specturms 
  model$period <- ShiftList[[1]]$DateTime[1/model$freq]
  print(model)
})

renderText({
  model <- spectrum(ShiftList[[input$shift_d]]$DailyError,log="no", plot=FALSE)
  model <- data.frame(freq = model$freq, spec = model$spec)
  model <- model[order(model$spec, decreasing = TRUE)[1:3],] #we select only largest 3 specturms 
  model$period <- ShiftList[[1]]$DateTime[1/model$freq]
  model <- model[complete.cases(model),]
  print(paste("Shift ", as.character(input$shift_d)," possible Period is: ", as.character(sum(model$period*model$spec)/sum(model$spec))))
})
```

  We see that all the shifts have possible period approximately equal to the length of a year.
  
  We now check the distribution of the errors to our estimation using these both type of smoothing, (daily average smoothing and shiftwise variation smoothing).
  
```{r message=FALSE}
quantile(PM10data$PM.Values-PM10data$Estimate)
library(ggplot2)
```

  We see that the first quartile and the third quartile is small in absolute value, suggesting a good estimation of the PM10 measures.
  
  Let us observe the residual plot as a time series. We should see a series with no special patterns.
  
```{r fig.width=10}
PM10data$FinalError <- PM10data$PM.Values - PM10data$Estimate
plot(PM10data$DateTime, PM10data$FinalError, type = "l", main = "Residual Plot", ylab = "Residuals", xlab = "Number of Days")
abline(h=0, col="blue")
```

  Let us also look at the distribution of the errors.

```{r message=FALSE}
ggplot(PM10data, aes(x=FinalError)) + geom_histogram(aes(y=..count../sum(..count..))) + geom_density(aes(y=18* ..count../sum(..count..)))
```

  The distrubtion of errors looks normal just by looking at the histogram. Let us take a look at the qqplot comparative to the normal distribution.
  
```{r}
error <- PM10data$FinalError
error <- (error - mean(error))/sd(error)
qqnorm(error)
abline(a=0, b=1, col = "blue", lwd=2)
```

  Finally we use a chi squared goodness of fit test to test whether the residuals are normally distirbuted.
  
```{r}
quants <- quantile(PM10data$FinalError, probs = seq(0,1,0.04))
cuts <- table(cut(PM10data$FinalError, breaks = quants))
breaks_cdf <- pnorm(quants, mean = 0, sd = sd(PM10data$FinalError))
breaks_cdf[1] <- 0
null.probs <- filter(breaks_cdf, filter = c(1,-1), sides = 1)
print(chisq.test(as.numeric(cuts), p=null.probs[-1]))
```

  As the p-value is low, we conclude with 99% confidence that the error are not distributed according to the normal distribution with mean 0.

## Conclusions

  The conclusion from the above analysis are described in the following points.
  
* The periodic pattern in smoothed daily averages exhibit the seasonal coefficients as shown above. We see that seasonal coefficient is lowest in August and is highest in the month of January. We conclude that PM10 measures is high in winters and is low in the later part of Summer, probably due to the rains.

* From the general behavior of trend, we see that the PM10 measures were low in first few years, and it increased in later years. However, for last few years, the PM10 measures seem to be decreasing.
  
* The pollution level in the shift 1 is mostly lower than the daily average pollution level. It is lower in winters and rises slightly above the daily average pollution level in middle of the year.

* The pollution level in the shift 2 is mostly above than the daily average pollution level. It is more in winters and falls about the daily average pollution level in middle of the year.

* The pollution level in the shift 3 follows a pattern of rising and falling. It is more in winters (beginning and end of the year) and falls sharply in the middle of the years with respect to the daily average. However, the general trend of this repetative pattern appears to be increasing. Hence, in first few years of the given dataset, the shift 3 seems to be mostly below the daily average level of pollution, whereas after that, shift 3 remains to be mostly above the daily average level of pollution.

* We see that the value of the PM10 falls below the regulation level at the middle of the year, from April-May to September-October. For the other times of the year, the value of PM10 remains above the regulation level.

* The anomality in PM10 measures of shift1 and shift2 tends to stay for about 2 weeks. For shift3, the anomality in PM10 measures do not carry forward any significant changes in PM10 measures of immediate next days.

* For shift1, the periodicity of the anomality of PM10 measures is extremely evident. For other shifts, these periodic pattern is not so obvious to see. From spectral analysis, we see that all the shifts have a periodic pattern with period being equal to 358, 372 and 365 days resepectively, about the length of a year.

* The distribution of the residuals do not assume a Normal distribution (with 99% confidence). However, the histogram shows that most of the residuals are concentrated near zero, suggesting that the estimation that we made is good.

# THANK YOU




<br style="line-height: 25em">


